import json
import os
from collections import defaultdict
from pathlib import Path

import torch
from torchvision import transforms
import seaborn as sns
import mlflow
import yaml
from matplotlib import pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from PIL import Image
import io, random



mlflow.set_tracking_uri('http://0.0.0.0:5000')

def get_project_paths():
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    with open(PROJECT_ROOT / "params.yaml") as f:
        config = yaml.safe_load(f)

    paths = config["paths"]
    return {
        "project_root": PROJECT_ROOT,
        "raw_dir": PROJECT_ROOT / paths["raw_data"],
        "processed_dir": PROJECT_ROOT / paths["processed_data"],
        "models_dir": PROJECT_ROOT / paths["models_dir"],
        "scripts_dir": PROJECT_ROOT / paths["scripts"],
        "image_dir": PROJECT_ROOT / paths["image_dir"],
        "vectors_dir": PROJECT_ROOT / paths["vectors_dir"],
        "logs_dir": PROJECT_ROOT / paths["logs_dir"],
        "optuna_results": PROJECT_ROOT / paths["optuna_results"],
    }

def get_project_root():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞."""
    return os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))



def log_confusion_matrix(all_preds, all_labels, model_name_tag):
    PROJECT_ROOT = Path(__file__).resolve().parent.parent

    paths = get_project_paths()

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
    labels = sorted(np.unique(all_labels))
    cm = confusion_matrix(all_labels, all_preds, labels=labels)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    plot_path = paths["image_dir"] / f"{model_name_tag}_confusion_matrix.png"
    plt.savefig(plot_path)
    mlflow.log_artifact(plot_path)
    plt.close()

def plot_losses(train_losses, val_losses, model_name_tag)->str:
    """
    –§—É–Ω–∫—Ü–∏—è –≥–æ—Ç–æ–≤–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–ø–µ—Ä–µ–¥–∞—á–∏ –≤ mlflow
    :param train_losses: –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
    :param val_losses: –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    :param model_name_tag:  –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞
    :return: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    """
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    with open(PROJECT_ROOT / "params.yaml") as f:
        paths = get_project_paths()

    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()


    plot_path =  paths["image_dir"] /f"training_loss_curve_{model_name_tag}.png"
    plt.savefig(plot_path)
    plt.close()

    return plot_path  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É




def plot_training_results():
    activation_keywords = ["relu", "tanh", "sigmoid", "leaky_relu", "elu", "swish", "mish"]
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    with open(PROJECT_ROOT / "params.yaml") as f:
        paths = get_project_paths()

    image_dir = paths["image_dir"]
    metrics_dir = paths["models_dir"]

    # 1. –°–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    all_images = list(image_dir.glob("*.png"))


    images = [img for img in all_images if "confusion_matrix" not in img.name]

    # 3. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    groups = defaultdict(list)
    for img in images:
        for act in activation_keywords:
            if act in img.name:
                groups[act].append(img)
                break
        else:
            groups["unknown"].append(img)

    # 4. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –ø–æ –¥–ª–∏–Ω–µ –∏–º–µ–Ω–∏
    for key in groups:
        groups[key].sort(key=lambda x: len(x.name))

    # 5. –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    for act_func, imgs in groups.items():
        print(f"\n=== Activation: {act_func.upper()} ===\n")
        n = len(imgs)
        rows = (n + 2) // 3  # –ø–æ 3 –≤ —Å—Ç—Ä–æ–∫—É
        fig, axes = plt.subplots(rows, 3, figsize=(18, 5 * rows), squeeze=False)
        axes = axes.flatten()

        for ax in axes[len(imgs):]:
            ax.axis('off')

        for ax, img_path in zip(axes, imgs):
            img = plt.imread(img_path)
            ax.imshow(img)
            ax.axis("off")
            ax.set_title(img_path.name, fontsize=10)

            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π JSON
            base_name = img_path.stem.replace("training_loss_curve_", "")
            json_name = f"{base_name}_train_metrics.json"  # –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ
            json_path = metrics_dir / json_name

            if json_path.exists():
                with open(json_path) as f:
                    metrics = json.load(f)
                info = (f"Best val: {metrics.get('best_val_loss', 'NA'):.4f}\n"
                        f"Train: {metrics.get('final_train_loss', 'NA'):.4f}\n"
                        f"Val: {metrics.get('final_val_loss', 'NA'):.4f}")
            else:
                info = "No metrics"

            ax.text(0.5, -0.15, info, ha="center", va="top",
                    fontsize=9, transform=ax.transAxes)


        plt.tight_layout()
        plt.show()

def show_feature_top_images(
    fc_path: Path,
    parquet_path: Path,
    num_features: int = 5,  # —Å–∫–æ–ª—å–∫–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤–∑—è—Ç—å (—Å—Ç—Ä–æ–∫)
    top_k: int = 6,         # —Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–∞ –Ω–µ–π—Ä–æ–Ω (–∫–æ–ª–æ–Ω–æ–∫)
    random_state: int = None,
    thumb_size: int = 96,   # —Ä–∞–∑–º–µ—Ä –º–∏–Ω–∏–∞—Ç—é—Ä
):
    """
    fc_path      ‚Äì .npy —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ñ–æ—Ä–º—ã (N, 1000)
    parquet_path ‚Äì .parquet —Å –∫–æ–ª–æ–Ω–∫–æ–π image.bytes
    """
    # reproducible randomness (–∏–ª–∏ –∫–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–æ–≤—ã–π –ø–æ—Ä—è–¥–æ–∫, –µ—Å–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å None)
    rnd = random.Random(random_state)

    # --- –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ----------------------------------------------------
    X = np.load(fc_path)              # (N, 1000)
    df = pd.read_parquet(parquet_path)
    assert len(X) == len(df), "–ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤!"

    N, D = X.shape
    feat_idx = rnd.sample(range(D), k=min(num_features, D))     # —Å–ª—É—á–∞–π–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã

    # --- —Ä–∏—Å—É–µ–º —Å–µ—Ç–∫—É --------------------------------------------------------
    fig, axes = plt.subplots(
        nrows=len(feat_idx), ncols=top_k, figsize=(top_k*2, num_features*2.2)
    )
    if len(feat_idx) == 1:
        axes = np.expand_dims(axes, 0)  # —É–Ω–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø

    for row, f in enumerate(feat_idx):
        # –±–µ—Ä—ë–º top-k –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–∞–Ω–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–∞
        top_indices = np.argsort(-X[:, f])[:top_k]

        for col, img_idx in enumerate(top_indices):
            ax = axes[row, col]
            # –∏–∑–≤–ª–µ–∫–∞–µ–º bytes ‚Üí PIL ‚Üí RGB ‚Üí thumbnail
            img_bytes = df.iloc[img_idx]['image']['bytes']
            img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
            img.thumbnail((thumb_size, thumb_size))

            ax.imshow(img)
            ax.axis("off")
            if col == 0:                       # –ø–æ–¥–ø–∏—Å–∞—Ç—å —Å—Ç—Ä–æ–∫—É —Å–ª–µ–≤–∞
                ax.set_ylabel(f"f{f}", rotation=0, labelpad=30, fontsize=9)

    plt.suptitle(
        f"–¢–æ–ø-{top_k} –∫–∞—Ä—Ç–∏–Ω–æ–∫\n–¥–ª—è {num_features} —Å–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤ fc1000",
        y=0.92, fontsize=12
    )
    plt.tight_layout()
    plt.show()



def show_random_fc_activations(
    fc_path: Path,
    parquet_path: Path,
    neuron_indices=None,   # —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∏—á; –µ—Å–ª–∏ None ‚Äî –≤—ã–±–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω–æ
    num_features: int = 10, # —Å–∫–æ–ª—å–∫–æ —Ñ–∏—á –ø–æ–∫–∞–∑–∞—Ç—å, –µ—Å–ª–∏ neuron_indices=None
    index: int = None,     # –∫–∞–∫–æ–π –ø—Ä–∏–º–µ—Ä –≤–∑—è—Ç—å; –µ—Å–ª–∏ None ‚Äî —Å–ª—É—á–∞–π–Ω—ã–π
    random_state: int = None
):
    """
    fc_path      ‚Äì .npy (N, 1000) —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    parquet_path ‚Äì .parquet —Å –∫–æ–ª–æ–Ω–∫–æ–π image.bytes
    """
    rnd = random.Random(random_state)

    # --- –∑–∞–≥—Ä—É–∑–∫–∞ ---
    X  = np.load(fc_path)                # (N, 1000) float32/64
    df = pd.read_parquet(parquet_path)   # –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å column 'image'

    assert len(X) == len(df), "–ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ fc_vector –∏ parquet!"

    N, D = X.shape
    if index is None:
        index = rnd.randrange(N)         # —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–∏–º–µ—Ä

    img_bytes = df.iloc[index]['image']['bytes']
    fc_vector = X[index]                 # (1000,)

    # --- –∫–∞–∫–∏–µ –Ω–µ–π—Ä–æ–Ω—ã –ø–æ–∫–∞–∑–∞—Ç—å ---
    if neuron_indices is None:
        neuron_indices = rnd.sample(range(D), k=min(num_features, D))
    else:
        # –∑–∞—â–∏—Ç–∞: –æ–±—Ä–µ–∑–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ > 999
        neuron_indices = [i for i in neuron_indices if 0 <= i < D]
        if len(neuron_indices) == 0:
            raise ValueError("–°–ø–∏—Å–æ–∫ neuron_indices –ø—É—Å—Ç –∏–ª–∏ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0‚Äì999")

    # --- –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ---
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))

    # –æ—Ä–∏–≥–∏–Ω–∞–ª
    img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    axs[0].imshow(img)
    axs[0].axis("off")
    axs[0].set_title(f"Image #{index}")

    # bar-chart
    values = fc_vector[neuron_indices]
    axs[1].bar(range(len(neuron_indices)), values)
    axs[1].set_xticks(range(len(neuron_indices)))
    axs[1].set_xticklabels([f"f{idx}" for idx in neuron_indices])
    axs[1].set_title("fc1000 activations")

    plt.tight_layout()
    plt.show()

# def show_activation_maps(conv3_out, max_channels=16):
#     """
#     conv3_out: torch.Tensor (C, H, W) –∏–ª–∏ (B, C, H, W)
#     –ü–æ–∫–∞–∑—ã–≤–∞–µ–º max_channels –ø–µ—Ä–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏–π.
#     """
#     paths = get_project_paths()
#     parquet_path = paths["raw_dir"] / "test.parquet",
#     if conv3_out.dim() == 4:
#         conv3_out = conv3_out[0]  # –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä –≤ –±–∞—Ç—á–µ (C, H, W)
#
#     n_channels = min(conv3_out.shape[0], max_channels)
#     fig, axes = plt.subplots(1, n_channels, figsize=(n_channels*2, 2))
#
#     for i in range(n_channels):
#         ax = axes[i] if n_channels > 1 else axes
#         act_map = conv3_out[i].cpu().numpy()
#         ax.imshow(act_map, cmap='viridis')
#         ax.axis('off')
#         ax.set_title(f"Ch {i}")
#
#     plt.show()
def show_activation_maps(
    conv3_out: torch.Tensor,
    idx: int = None,          # –∫–∞–∫–æ–π –ø—Ä–∏–º–µ—Ä –≤–∑—è—Ç—å –∏–∑ parquet; –µ—Å–ª–∏ None, –Ω—É–∂–µ–Ω img_bytes
    img_bytes: bytes = None,  # –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–µ—Ä–µ–¥–∞—Ç—å
    max_channels: int = 16
):
    """
    conv3_out ‚Äî Tensor (C,H,W) –∏–ª–∏ (B,C,H,W) c –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏ —ç—Ç–æ–≥–æ –∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    idx       ‚Äî –∏–Ω–¥–µ–∫—Å –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ test.parquet (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–µ–µ, –µ—Å–ª–∏ img_bytes –Ω–µ –∑–∞–¥–∞–Ω).
    img_bytes ‚Äî –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ—Ç parquet).
    """

    # --- –¥–æ—Å—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª ----------------------------------------------------
    if img_bytes is None:
        if idx is None:
            raise ValueError("–ù—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –ª–∏–±–æ idx, –ª–∏–±–æ img_bytes!")
        paths = get_project_paths()
        parquet_path = paths["raw_dir"] / "test.parquet"
        df = pd.read_parquet(parquet_path)
        img_bytes = df.iloc[idx]["image"]["bytes"]

    img = Image.open(io.BytesIO(img_bytes)).convert("RGB")

    # --- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º conv3_out -> (C,H,W) ------------------------------------
    if conv3_out.dim() == 4:
        conv3_out = conv3_out[0]  # (C,H,W)

    n_channels = min(conv3_out.shape[0], max_channels)

    # --- —Ä–∏—Å—É–µ–º --------------------------------------------------------------
    fig_cols = n_channels + 1
    fig, axes = plt.subplots(1, fig_cols, figsize=(2*fig_cols, 2.5))

    # –æ—Ä–∏–≥–∏–Ω–∞–ª
    axes[0].imshow(img)
    axes[0].set_title("Original")
    axes[0].axis("off")

    # –∫–∞—Ä—Ç—ã –∞–∫—Ç–∏–≤–∞—Ü–∏–π
    for i in range(n_channels):
        ax = axes[i+1]
        fmap = conv3_out[i].cpu().numpy()
        ax.imshow(fmap, cmap="viridis")
        ax.set_title(f"Ch {i}")
        ax.axis("off")

    plt.tight_layout()
    plt.show()



def grad_cam(img_bgr, class_idx=None, thr=0.4):
    from nn_train import MyCNN
    import cv2

    paths = get_project_paths()
    model_path = paths["models_dir"] / "mish_best_final_model_new_vers.pt"
    activation = "mish"

    dropout = 0.2
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = MyCNN(activation=activation, dropout=dropout).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))

    model.eval()

    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (224, 224))  # üëà –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!
    tensor = transforms.ToTensor()(img_resized).unsqueeze(0).to(device)

    # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥: logits, features, conv3_out
    logits, features, conv3_out = model(tensor)

    if class_idx is None:
        class_idx = (logits > 0).int().item()  # 0 –∏–ª–∏ 1, —Ç–≤–æ—è –∑–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–∞—è

    score = logits[0, 0]

    model.zero_grad()
    score.backward(retain_graph=True)

    # –ü–æ–ª—É—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã conv3_out (B, C, H, W)
    gradients = model.gradients.cpu().data.numpy()[0]  # (C, H, W)
    activations = conv3_out.cpu().data.numpy()[0]      # (C, H, W)

    # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –æ—Å—è–º ‚Äî –≤–µ—Å–∞ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤
    weights = np.mean(gradients, axis=(1, 2))          # (C,)

    # Grad-CAM = –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
    cam = np.zeros(activations.shape[1:], dtype=np.float32)  # (H, W)
    for i, w in enumerate(weights):
        cam += w * activations[i]

    # –†–µ–ª—É –Ω–∞ –∫–∞—Ä—Ç–µ
    cam = np.maximum(cam, 0)
    cam = cam / cam.max()  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è 0..1

    # –ü—Ä–∏–≤–æ–¥–∏–º cam –∫ —Ä–∞–∑–º–µ—Ä—É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    cam = cv2.resize(cam, (img_bgr.shape[1], img_bgr.shape[0]))

    # –ù–∞–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    overlayed = heatmap * 0.4 + img_rgb * 0.6
    overlayed = np.uint8(overlayed)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å, raw score –∏ –∫–∞—Ä—Ç–∏–Ω–∫—É —Å CAM
    return class_idx, score.item(), overlayed, cam


def show_grad_cam_results(original_img, cam_overlayed, cam_mask):
    """
    original_img: RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (np.array)
    cam_overlayed: RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–∞–ª–æ–∂–µ–Ω–Ω–æ–π —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç–æ–π
    cam_mask: np.array —Å float32, –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1
    """
    fig, axs = plt.subplots(1, 3, figsize=(18, 6))

    axs[0].imshow(original_img)
    axs[0].set_title("Original Image")
    axs[0].axis("off")

    axs[1].imshow(cam_overlayed)
    axs[1].set_title("Grad-CAM Overlay")
    axs[1].axis("off")

    im = axs[2].imshow(cam_mask, cmap='jet')
    axs[2].set_title("Grad-CAM Mask")
    axs[2].axis("off")
    fig.colorbar(im, ax=axs[2], fraction=0.046, pad=0.04)

    plt.tight_layout()
    plt.show()